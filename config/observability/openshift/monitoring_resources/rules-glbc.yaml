# Code generated by dhall-to-yaml.  DO NOT EDIT.
groups:
  - name: deadmanssnitch
    rules:
      - alert: DeadMansSwitch
        annotations:
          description: |2
              This is an alert meant to ensure that the entire alerting pipeline
              is functional.
              This alert is always firing, therefore it should always be firing
              in Alertmanager
              and always fire against a receiver. There are integrations with
              various notification
              mechanisms that send a notification when this alert is not firing.
              For example the
              "DeadMansSnitch" integration in PagerDuty.
        expr: "vector(1)"
        labels:
          name: DeadMansSwitchAlert
  - name: glbc
    rules:
      - alert: GLBCTargetDown
        annotations:
          description: "The GLBC Prometheus Target is down. Either the GLBC component is not running, is misconfigured, or the metrics endpoint is not responding."
          runbook_url: https://github.com/Kuadrant/kcp-glbc/blob/main/docs/observability/runbooks/glbctargetdown.adoc
          summary: GLBC Prometheus Target is down
        expr: "absent(up{container=\"manager\",job=~\".*kcp-glbc-controller-manager\"}) or up{container=\"manager\",job=~\".*kcp-glbc-controller-manager\"} != 1"
        for: "5m"
        labels:
          severity: critical
      - alert: HighDNSProviderErrorRate
        annotations:
          description: "Excessive errors - The error rate is {{ $value }}, which is greater than the threshold which is 1%"
          runbook_url: https://github.com/Kuadrant/kcp-glbc/blob/main/docs/observability/runbooks/HighDNSProviderErrorRate.adoc
          summary: High DNS Provider Error Rate
        expr: "sum(rate(glbc_aws_route53_request_errors_total{}[5m])) by(pod) / sum(rate(glbc_aws_route53_request_total{}[5m])) by(pod) > 0.01"
        for: "60m"
        labels:
          severity: warning
